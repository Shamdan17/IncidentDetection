{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dataset\n",
    "from util import (\n",
    "    get_place_to_index_mapping,\n",
    "    get_incident_to_index_mapping\n",
    ")\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, Flatten, Permute\n",
    "from keras import Sequential\n",
    "import keras.backend as kb\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_path = \"/kuacc/users/asafaya19/cv-project\"\n",
    "train_json = os.path.join(abs_path ,\"eccv_train.json\")\n",
    "val_json = os.path.join(abs_path ,\"eccv_val.json\")\n",
    "data_dir = os.path.join(abs_path, \"data\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "train_paths = json.loads(open(train_json).readline())\n",
    "val_paths = json.loads(open(val_json).readline())\n",
    "\n",
    "place_to_idx = get_place_to_index_mapping()\n",
    "incident_to_idx = get_incident_to_index_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(paths,file_dir, threshold=1000):\n",
    "    train_set = []\n",
    "    for path in tqdm(paths, leave=False):\n",
    "    #     print(path)\n",
    "        if not os.path.exists(os.path.join(file_dir, path)):\n",
    "            continue\n",
    "        # Make sure image is not corrupt, try importing it\n",
    "        try:\n",
    "            PIL.Image.open(os.path.join(file_dir, path))\n",
    "        except:\n",
    "            continue\n",
    "        nump = len(place_to_idx)+1\n",
    "        numi = len(incident_to_idx)+1\n",
    "        place_labels = np.zeros(nump, np.float32)\n",
    "        place_weights = np.zeros(nump, np.float32)\n",
    "        incident_labels = np.zeros(numi, np.float32)\n",
    "        incident_weights = np.zeros(numi, np.float32)\n",
    "\n",
    "        incidents = paths[path][\"incidents\"]\n",
    "        for k in incidents:\n",
    "            lbl = incidents[k]\n",
    "            if lbl==1:\n",
    "                # We are sure this instance is only this incident\n",
    "                incident_labels[incident_to_idx[k]]=1\n",
    "                incident_weights = np.ones(numi, np.float32)\n",
    "            else:\n",
    "                # We are only sure that this image is not that incident\n",
    "                incident_weights[incident_to_idx[k]]=1\n",
    "        if len(incidents)==0:\n",
    "            # No incident\n",
    "            incident_labels[-1]=1\n",
    "            incident_weights = np.ones(numi, np.float32)\n",
    "\n",
    "        places = paths[path][\"places\"]\n",
    "        for k in places:\n",
    "            lbl = places[k]\n",
    "            if lbl==1:\n",
    "                # We are sure this instance is only this incident\n",
    "                place_labels[place_to_idx[k]]=1\n",
    "                place_weights = np.ones(nump, np.float32)\n",
    "            else:\n",
    "                # We are only sure that this image is not that incident\n",
    "                place_weights[place_to_idx[k]]=1\n",
    "        if len(places)==0:\n",
    "            # No place\n",
    "            place_labels[-1]=1\n",
    "            place_weights = np.ones(nump, np.float32)\n",
    "\n",
    "\n",
    "        train_set.append({\n",
    "            \"path\":path,\n",
    "            \"incident_labels\":incident_labels,\n",
    "            \"incident_weights\":incident_weights,\n",
    "            \"incidents\":np.vstack((incident_labels, incident_weights)),\n",
    "            \"place_labels\":place_labels,\n",
    "            \"place_weights\":place_weights,\n",
    "            \"place\":np.vstack((place_labels, place_weights))\n",
    "        })\n",
    "        if len(train_set)>=threshold:\n",
    "            break\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpreprocessfunc():\n",
    "    mean = np.asarray([0.485, 0.456, 0.406]).reshape(3, 1, 1).astype(np.float32)\n",
    "    std = np.asarray([0.229, 0.224, 0.225]).reshape(3, 1, 1).astype(np.float32)\n",
    "    def preprocessfunc(img):\n",
    "        img /= 255\n",
    "        img -= mean\n",
    "        img /= std\n",
    "        return img\n",
    "    return preprocessfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_final_model():\n",
    "    \n",
    "    \n",
    "    inp = keras.Input(shape=(3, 256, 256))\n",
    "#     cropped = keras.layers.experimental.preprocessing.RandomCrop(224, 224)(inp)\n",
    "    \n",
    "    loaded_model = model_from_json(open('models/trunk.json', 'r').read())(inp)\n",
    "    loaded_model.load_weights(\"models/trunk.h5\")\n",
    "\n",
    "    incident_proj = Dense(len(incident_to_idx)+1, name=\"incidents_projection\")(trunk)\n",
    "    incident_proj.se(\"models\")\n",
    "    places_proj = Dense(len(place_to_idx)+1, name=\"places_projection\")(trunk)\n",
    "    \n",
    "    mdl = keras.Model(inputs=inp, outputs=[incident_proj, places_proj])    \n",
    "    \n",
    "    mdl.layers[2].set_weights(np.load(\"models/incident.npy\"))\n",
    "    \n",
    "    \n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclosure to retain state\n",
    "def get_weighted_accuracy():\n",
    "    m = keras.metrics.CategoricalAccuracy()\n",
    "    def weighted_accuracy(y_true, y_preds):\n",
    "        y_true = tf.reshape(y_true, (bs, 2, -1))\n",
    "        y_true_lbls = y_true[:,0,:]\n",
    "        return m(y_true_lbls, y_preds)\n",
    "    return weighted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_preds):\n",
    "    bce = keras.losses.BinaryCrossentropy(keras.losses.Reduction.NONE)\n",
    "#     tf.print(y_true)\n",
    "#     tf.print(y_preds)\n",
    "#     print(y_true.shape)\n",
    "#     print(y_preds.shape)\n",
    "    bs = y_true.shape[0]\n",
    "    y_true = tf.reshape(y_true, (bs, 2, -1))\n",
    "    y_true_lbls = y_true[:,0,:]\n",
    "    y_true_weights = y_true[:,1,:]\n",
    "    bce_loss = bce(y_true_lbls, y_preds)\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "#     return bce_loss\n",
    "    return tf.reduce_sum(tf.multiply(bce_loss, y_true_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = get_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_proj = Dense(len(incident_to_idx)+1, name=\"incidents_projection\")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "# inp = keras.Input(shape=(3, 256, 256))\n",
    "# permute = Permute((2, 3, 1))\n",
    "# cropped = keras.layers.experimental.preprocessing.RandomCrop(224, 224)\n",
    "# permuteback = Permute((3, 1, 2))\n",
    "# loaded_model = model_from_json(open('models/trunk.json', 'r').read())\n",
    "# loaded_model.load_weights(\"models/trunk.h5\")\n",
    "\n",
    "# # Define Sequential model with 3 layers\n",
    "# trunk_model = keras.Sequential(\n",
    "#     [\n",
    "#         inp,\n",
    "#         permute,\n",
    "#         cropped,\n",
    "#         permuteback,\n",
    "#         loaded_model,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# incident_proj = Dense(len(incident_to_idx)+1, name=\"incidents_projection\")(trunk_model)\n",
    "# places_proj = Dense(len(place_to_idx)+1, name=\"places_projection\")(trunk_model)\n",
    "\n",
    "# mdl = keras.Model(inputs=trunk_model, outputs=[incident_proj, places_proj])    \n",
    "\n",
    "\n",
    "class FinalModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FinalModel, self).__init__()\n",
    "        self.inp = keras.Input(shape=(3, 256, 256))\n",
    "        self.permute = Permute((2, 3, 1))\n",
    "        self.cropped = keras.layers.experimental.preprocessing.RandomCrop(224, 224)\n",
    "        self.permuteback = Permute((3, 1, 2))\n",
    "        self.loaded_model = model_from_json(open(os.path.join(abs_path,'models/trunk.json'), 'r').read())\n",
    "        self.loaded_model.load_weights(os.path.join(abs_path,\"models/trunk.h5\"))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "#         x = self.inp(inputs)\n",
    "        x = self.permute(inputs)\n",
    "        x = self.cropped(x)\n",
    "        x = self.permuteback(x)\n",
    "        x = self.loaded_model(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "mdl = FinalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2aeece071590>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mdl.layers[2].set_weights(np.load(\"models/incident.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = get_dataset(train_paths, train_dir, 1000)\n",
    "val_set = get_dataset(val_paths, val_dir, 1000)\n",
    "\n",
    "train_df = pd.DataFrame(train_set)\n",
    "val_df = pd.DataFrame(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "imgen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=getpreprocessfunc(),\n",
    ")\n",
    "\n",
    "imgen = imgen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=train_dir,\n",
    "    x_col=\"path\",\n",
    "    y_col=[\"incidents\", \"place\"],\n",
    "    weight_col=None,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=None,\n",
    "    class_mode=\"multi_output\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=True,\n",
    "    save_to_dir=None,\n",
    "    save_prefix=\"\",\n",
    "    save_format=\"png\",\n",
    "    subset=None,\n",
    "    interpolation=\"nearest\",\n",
    "    validate_filenames=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"incidents_projection\": weighted_loss,\n",
    "    \"places_projection\": weighted_loss,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "mdl = get_final_model()\n",
    "\n",
    "mdl.compile(optimizer=opt, loss=losses, metrics=[get_weighted_accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(imgen)\n",
    "o = mdl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       "array([[0.47994307, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.6543304 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.17853671],\n",
       "       [1.3494209 , 0.        , 1.6460733 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.2620056 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.7307619 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.3992574 ],\n",
       "       [0.46037802, 0.        , 0.65531677, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[11  3 28  0 13 17  1 34  4 14 24  1 31 35 20 23 27 31 14 14 27  1 19 30\n",
      " 28  3 10 38  4  8 40 35 27 31  8 16  7 10 38 41  7 35 37 37 35 27 31 28\n",
      " 16  7 24 22 10 34 24 10 31 23 41 27 28 37  8  2], shape=(64,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[49 49 49 49 49 49 39 21 11 49 49 24 20  4 49 49 49 13 49 16 37 49 25 49\n",
      " 49 49 49 49 11  4 10 49 37 13 49 45 49 49 49  9 49 49 49 49  4 49 49 49\n",
      " 49 49 49 20 49 45 48 49 20 49  1 37 49 44 15 49], shape=(64,), dtype=int64)\n",
      "[ 0  0  0  0  0  0  1 34  4  0  0  1 31 35  0  0  0 31  0 14 27  0 19  0\n",
      "  0  0  0  0  4  8 33  0 27 31  0 16  0  0  0 41  7  0  0  0 35  0  0  0\n",
      "  0  0  0 22  0 34 24  0 31  0 41 27  0 37  8  0]\n",
      "[49 49 49 49 49 49  0  0  0 49 49 24 20  0 49 49 49  0 49  0 37 49  0 49\n",
      " 49 49 49 49  0  0 10 49 37 13 49  0 49 49 49  0  0 49 49 49  4 49 49 49\n",
      " 49 49 49  0 49  0 48 49 20 49  1  0 49 44  0 49]\n"
     ]
    }
   ],
   "source": [
    "# itr = tqdm(imgen)\n",
    "for x, y in imgen:\n",
    "#     print(type(x), type(y))\n",
    "    y1 = y[0]\n",
    "    y2 = y[1]\n",
    "    bs = y1.shape[0]\n",
    "#     print(, \"\\r\")\n",
    "    out = mdl.predict(x)\n",
    "    print(tf.argmax(out[0], axis=1))\n",
    "    print(tf.argmax(out[1], axis=1))\n",
    "#     print([y1.reshape(bs, -1), y2.reshape(bs, -1)])\n",
    "    print(np.argmax(y1[:,0,:], axis=1))\n",
    "    print(np.argmax(y2[:,0,:], axis=1))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Avoid hogging up gpu memory \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dataset\n",
    "from util import (\n",
    "    get_place_to_index_mapping,\n",
    "    get_incident_to_index_mapping,\n",
    "    get_index_to_incident_mapping,\n",
    "    get_index_to_place_mapping\n",
    ")\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, Flatten, Permute\n",
    "from keras import Sequential\n",
    "import keras.backend as kb\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from collections import defaultdict\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_path = \"/kuacc/users/asafaya19/cv-project\"\n",
    "train_json = os.path.join(abs_path ,\"eccv_train.json\")\n",
    "val_json = os.path.join(abs_path ,\"eccv_val.json\")\n",
    "data_dir = os.path.join(abs_path, \"data\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "train_paths = json.loads(open(train_json).readline())\n",
    "val_paths = json.loads(open(val_json).readline())\n",
    "\n",
    "place_to_idx = get_place_to_index_mapping()\n",
    "incident_to_idx = get_incident_to_index_mapping()\n",
    "\n",
    "index_to_incident_mapping = get_index_to_incident_mapping()\n",
    "index_to_place_mapping = get_index_to_place_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(paths,file_dir, threshold=1000):\n",
    "    train_set = []\n",
    "    for path in tqdm(paths, leave=False):\n",
    "        if not os.path.exists(os.path.join(file_dir, path)):\n",
    "            continue\n",
    "        # Make sure image is not corrupt, try importing it\n",
    "        try:\n",
    "            img = PIL.Image.open(os.path.join(file_dir, path))\n",
    "            img.resize((224, 224))\n",
    "        except:\n",
    "            continue\n",
    "        nump = len(place_to_idx) + 1\n",
    "        numi = len(incident_to_idx) + 1\n",
    "        place_labels = np.zeros(nump, np.float32)\n",
    "        place_weights = np.zeros(nump, np.float32)\n",
    "        incident_labels = np.zeros(numi, np.float32)\n",
    "        incident_weights = np.zeros(numi, np.float32)\n",
    "\n",
    "        incidents = paths[path][\"incidents\"]\n",
    "        for k in incidents:\n",
    "            lbl = incidents[k]\n",
    "            if lbl==1:\n",
    "                # We are sure this instance is only this incident\n",
    "                incident_labels[incident_to_idx[k]]=1\n",
    "                incident_weights = np.ones(numi, np.float32)\n",
    "            else:\n",
    "                # We are only sure that this image is not that incident\n",
    "                incident_weights[incident_to_idx[k]]=1\n",
    "        if len(incidents)==0:\n",
    "            # No incident\n",
    "            incident_labels[-1]=1\n",
    "            incident_weights = np.ones(numi, np.float32)\n",
    "\n",
    "        places = paths[path][\"places\"]\n",
    "        for k in places:\n",
    "            lbl = places[k]\n",
    "            if lbl==1:\n",
    "                # We are sure this instance is only this incident\n",
    "                place_labels[place_to_idx[k]]=1\n",
    "                place_weights = np.ones(nump, np.float32)\n",
    "            else:\n",
    "                # We are only sure that this image is not that incident\n",
    "                place_weights[place_to_idx[k]]=1\n",
    "        if len(places)==0:\n",
    "            # No place\n",
    "            place_labels[-1]=1\n",
    "            place_weights = np.ones(nump, np.float32)\n",
    "\n",
    "\n",
    "        train_set.append({\n",
    "            \"path\":path,\n",
    "            \"incident_labels\":incident_labels,\n",
    "            \"incident_weights\":incident_weights,\n",
    "            \"incidents\":np.vstack((incident_labels, incident_weights)),\n",
    "            \"place_labels\":place_labels,\n",
    "            \"place_weights\":place_weights,\n",
    "            \"place\":np.vstack((place_labels, place_weights))\n",
    "        })\n",
    "        if len(train_set)>=threshold:\n",
    "            break\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpreprocessfunc():\n",
    "    mean = np.asarray([0.485, 0.456, 0.406]).reshape(3, 1, 1).astype(np.float32)\n",
    "    std = np.asarray([0.229, 0.224, 0.225]).reshape(3, 1, 1).astype(np.float32)\n",
    "    def preprocessfunc(img):\n",
    "        img /= 255\n",
    "        img -= mean\n",
    "        img /= std\n",
    "        return img\n",
    "    return preprocessfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enclosure to retain state\n",
    "def get_weighted_accuracy():\n",
    "    m = keras.metrics.CategoricalAccuracy()\n",
    "    def weighted_accuracy(y_true, y_preds):\n",
    "        y_true = tf.reshape(y_true, (bs, 2, -1))\n",
    "        y_true_lbls = y_true[:,0,:]\n",
    "        return m(y_true_lbls, y_preds)\n",
    "    return weighted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(y_true, y_preds):\n",
    "    bce = keras.losses.BinaryCrossentropy(keras.losses.Reduction.NONE)\n",
    "    bs = y_true.shape[0]\n",
    "    y_true = tf.reshape(y_true, (bs, 2, -1))\n",
    "    y_true_lbls = y_true[:,0,:]\n",
    "    y_true_weights = y_true[:,1,:]\n",
    "    bce_loss = bce(y_true_lbls, y_preds)\n",
    "    return tf.reduce_sum(tf.multiply(bce_loss, y_true_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "class FinalModel(keras.Model):\n",
    "    def __init__(self, trunk_model, incident_weights, place_weights):\n",
    "        super(FinalModel, self).__init__()\n",
    "        self.permute = Permute((2, 3, 1))\n",
    "        self.cropped = keras.layers.experimental.preprocessing.RandomCrop(224, 224)\n",
    "        self.permuteback = Permute((3, 1, 2))\n",
    "        self.trunk_model = trunk_model\n",
    "        self.incident_proj = Dense(len(incident_to_idx), input_shape=(1024,), name=\"incidents_projection\", weights=incident_weights)\n",
    "        self.places_proj = Dense(len(place_to_idx), input_shape=(1024,), name=\"places_projection\", weights=place_weights)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.permute(inputs)\n",
    "        x = self.cropped(x)\n",
    "        x = self.permuteback(x)\n",
    "        x = self.trunk_model(x)\n",
    "        \n",
    "        return self.incident_proj(x), self.places_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics\"\"\"\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place_name_from_mapping(idx):\n",
    "    name = None\n",
    "    if idx in index_to_place_mapping:\n",
    "        name = index_to_place_mapping[idx]\n",
    "    else:\n",
    "        name = \"no place\"\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_incident_name_from_mapping(idx):\n",
    "    name = None\n",
    "    if idx in index_to_incident_mapping:\n",
    "        name = index_to_incident_mapping[idx]\n",
    "    else:\n",
    "        name = \"no incident\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, pred_scores, topk=1):\n",
    "    if y_true.sum() == 0:\n",
    "        return 100.0\n",
    "    \n",
    "    idx = np.argpartition(pred_scores, kth=-topk, axis=1)[:, -topk:]\n",
    "    correct_topk = y_true[np.arange(idx.shape[0])[:, np.newaxis], idx].sum()\n",
    "    num_pos_in_batch = y_true.sum()\n",
    "\n",
    "    return correct_topk * ( 100.0 / num_pos_in_batch ) \n",
    "\n",
    "def get_acc_num_correct_out_of_total(y_true, pred_scores, topk=1):\n",
    "    \n",
    "    idx = np.argpartition(pred_scores, kth=-topk, axis=1)[:, -topk:]\n",
    "    correct_topk = y_true[np.arange(idx.shape[0])[:, np.newaxis], idx].sum()\n",
    "    num_pos_in_batch = y_true.sum()\n",
    "\n",
    "    return correct_topk, num_pos_in_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, datasize, epoch=1, writer=None, activation=\"sigmoid\"):\n",
    "    \"\"\"Run validation of the model with metrics.\n",
    "\n",
    "    Args:\n",
    "        args:\n",
    "        val_loader:\n",
    "        all_models:\n",
    "\n",
    "    Returns:\n",
    "        float: incident mAP + place mAP\n",
    "    \"\"\"\n",
    "    # holds the metrics\n",
    "    a_v_incident_top1 = AverageMeter()\n",
    "    a_v_place_top1 = AverageMeter()\n",
    "    a_v_incident_top5 = AverageMeter()\n",
    "    a_v_place_top5 = AverageMeter()\n",
    "\n",
    "    top1_num_correct_all, top1_num_total_all = 0, 0\n",
    "    top5_num_correct_all, top5_num_total_all = 0, 0\n",
    "\n",
    "    if activation == \"softmax\":\n",
    "        # in this case, include \"no incident\" and \"no place\"\n",
    "        ap_incidents = [[] for i in range(len(index_to_incident_mapping) + 1)]\n",
    "        ap_places = [[] for i in range(len(index_to_place_mapping) + 1)]\n",
    "    elif activation == \"sigmoid\":\n",
    "        ap_incidents = [[] for i in range(len(index_to_incident_mapping))]\n",
    "        ap_places = [[] for i in range(len(index_to_place_mapping))]\n",
    "\n",
    "    # set end time as current time before training on a batch\n",
    "    for batch_iteration, val_data_input in enumerate(val_loader):\n",
    "\n",
    "        image_v = val_data_input[0]\n",
    "        \n",
    "        target_i_v = val_data_input[1][0][:,0,:-1] # we add :-1 for sigmoid\n",
    "        weight_i_v = val_data_input[1][0][:,1,:-1]\n",
    "\n",
    "        target_p_v = val_data_input[1][1][:,0,:-1]\n",
    "        weight_p_v = val_data_input[1][1][:,1,:-1]\n",
    "\n",
    "        # compute output \n",
    "        output = model.predict(image_v)\n",
    "        incident_output = sigmoid(output[0]) if activation == \"sigmoid\" else softmax(output[0], axis=1)\n",
    "        place_output = sigmoid(output[1]) if activation == \"sigmoid\" else softmax(output[1], axis=1)\n",
    "\n",
    "        # prepare for average precison calculations\n",
    "        # make sure this is batch size\n",
    "        assert incident_output.shape[0] == place_output.shape[0]\n",
    "\n",
    "        for batch_idx in range(incident_output.shape[0]):\n",
    "            \n",
    "            np_incident_output = incident_output[batch_idx]\n",
    "            np_target_i_v = target_i_v[batch_idx]\n",
    "            np_weight_i_v = weight_i_v[batch_idx]\n",
    "\n",
    "            np_incident_output_shape = np_incident_output.shape[0]\n",
    "            if activation == \"softmax\":\n",
    "                np_incident_output_shape -= 1\n",
    "\n",
    "            for class_idx in range(np_incident_output_shape):\n",
    "                confidence = np_incident_output[class_idx]\n",
    "                label = np_target_i_v[class_idx]\n",
    "                weight = np_weight_i_v[class_idx]\n",
    "\n",
    "                pos = (label == 1 and weight > 0)\n",
    "                neg = (label == 0 and weight > 0)\n",
    "                if pos:\n",
    "                    ap_incidents[class_idx].append((confidence, 1))\n",
    "                elif neg:\n",
    "                    ap_incidents[class_idx].append((confidence, 0))\n",
    "\n",
    "            np_place_output = place_output[batch_idx]\n",
    "            np_target_p_v = target_p_v[batch_idx]\n",
    "            np_weight_p_v = weight_p_v[batch_idx]\n",
    "\n",
    "            np_place_output_shape = np_place_output.shape[0]\n",
    "            if activation == \"softmax\":\n",
    "                np_place_output_shape -= 1\n",
    "\n",
    "            for class_idx in range(np_place_output_shape):\n",
    "                confidence = np_place_output[class_idx]\n",
    "                label = np_target_p_v[class_idx]\n",
    "                weight = np_weight_p_v[class_idx]\n",
    "\n",
    "                pos = (label == 1 and weight > 0)\n",
    "                neg = (label == 0 and weight > 0)\n",
    "                if pos:\n",
    "                    ap_places[class_idx].append((confidence, 1))\n",
    "                elif neg:\n",
    "                    ap_places[class_idx].append((confidence, 0))\n",
    "\n",
    "        # incident accuracy\n",
    "        incident_prec1 = accuracy(incident_output, target_i_v, topk=1)\n",
    "        incident_prec5 = accuracy(incident_output, target_i_v, topk=5)\n",
    "\n",
    "        top1_num_correct, top1_num_total = get_acc_num_correct_out_of_total(incident_output, target_i_v, topk=1)\n",
    "        top1_num_correct_all += top1_num_correct\n",
    "        top1_num_total_all += top1_num_total\n",
    "        top5_num_correct, top5_num_total = get_acc_num_correct_out_of_total(incident_output, target_i_v, topk=5)\n",
    "        top5_num_correct_all += top5_num_correct\n",
    "        top5_num_total_all += top5_num_total\n",
    "\n",
    "        # place accuracy\n",
    "        place_prec1 = accuracy(place_output, target_p_v, topk=1)\n",
    "        place_prec5 = accuracy(place_output, target_p_v, topk=5)\n",
    "\n",
    "        a_v_place_top1.update(place_prec1, image_v.shape[0])\n",
    "        a_v_incident_top1.update(incident_prec1, image_v.shape[0])\n",
    "        a_v_place_top5.update(place_prec5, image_v.shape[0])\n",
    "        a_v_incident_top5.update(incident_prec5, image_v.shape[0])\n",
    "\n",
    "        # measure elapsed time\n",
    "        if batch_iteration % 100 == 0:\n",
    "            print('Evaluating: [{0}/{1}]\\t'\n",
    "                  'Incident Prec@1 {a_v_incident_top1.val:.3f} ({a_v_incident_top1.avg:.3f})\\t'\n",
    "                  'Place Prec@1 {a_v_place_top1.val:.3f} ({a_v_place_top1.avg:.3f})\\t'\n",
    "                  'Place Prec@5 {a_v_place_top5.val:.3f} ({a_v_place_top5.avg:.3f})\\t'\n",
    "                  'Incident Prec@5 {a_v_incident_top5.val:.3f} ({a_v_incident_top5.avg:.3f})\\t'.format(\n",
    "                batch_iteration,\n",
    "                len(val_loader),\n",
    "                a_v_incident_top1=a_v_incident_top1,\n",
    "                a_v_place_top1=a_v_place_top1,\n",
    "                a_v_incident_top5=a_v_incident_top5,\n",
    "                a_v_place_top5=a_v_place_top5))\n",
    "            \n",
    "        if batch_iteration == np.ceil(datasize / image_v.shape[0]):\n",
    "            break\n",
    "\n",
    "    print(\"\\nCalculating APs\\n\")\n",
    "    # threshold are [0.0, 0.1, ..., 1.0] (11 values)\n",
    "    thresholds = [round(i, 2) for i in list(np.linspace(0.0, 1.0, num=11))]\n",
    "\n",
    "    # holds average precision for each class\n",
    "    ap_incident_dict = {}\n",
    "    ap_place_dict = {}\n",
    "\n",
    "    # ap for incidents\n",
    "    for i in range(len(ap_incidents)):\n",
    "        class_points = ap_incidents[i]\n",
    "        name = get_incident_name_from_mapping(i)\n",
    "        if len(class_points) == 0:\n",
    "            print(\"{} has no relevant labels\".format(name))\n",
    "            ap_incident_dict[name] = 1\n",
    "            continue\n",
    "\n",
    "        sorted_by_confidence = sorted(\n",
    "            class_points, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        count = 0\n",
    "        pos_targets = 0\n",
    "        max_prec = defaultdict(int)\n",
    "        total_positives = int(np.sum(np.array(class_points)[:, 1]))\n",
    "        if total_positives == 0:\n",
    "            print(\"{} has no pos labels\".format(name))\n",
    "            continue  # alert in this case maybe\n",
    "\n",
    "        # go in order\n",
    "        for confidence, label in sorted_by_confidence:\n",
    "            count += 1\n",
    "            if label == 1:\n",
    "                pos_targets += 1\n",
    "            precision = pos_targets / count\n",
    "            recall = pos_targets / total_positives\n",
    "\n",
    "            for thresh in thresholds:\n",
    "                if recall >= thresh:\n",
    "                    max_prec[thresh] = max(max_prec[thresh], precision)\n",
    "            if pos_targets == total_positives:\n",
    "                break\n",
    "        l = list(max_prec.values())\n",
    "        average_precision = sum(l) / len(l)\n",
    "        ap_incident_dict[get_incident_name_from_mapping(i)] = average_precision\n",
    "\n",
    "    # repeat for places\n",
    "    for i in range(len(ap_places)):\n",
    "        class_points = ap_places[i]\n",
    "        name = get_place_name_from_mapping(i)\n",
    "        if len(class_points) == 0:\n",
    "            print(\"{} has no relevant labels\".format(name))\n",
    "            ap_place_dict[name] = 1\n",
    "            continue\n",
    "\n",
    "        sorted_by_confidence = sorted(\n",
    "            class_points, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        count = 0\n",
    "        pos_targets = 0\n",
    "        max_prec = defaultdict(int)\n",
    "        total_positives = int(np.sum(np.array(class_points)[:, 1]))\n",
    "        if total_positives == 0:\n",
    "            print(\"{} has no pos labels\".format(name))\n",
    "            continue  # alert in this case maybe\n",
    "\n",
    "        # go in order\n",
    "        for confidence, label in sorted_by_confidence:\n",
    "            count += 1\n",
    "            if label == 1:\n",
    "                pos_targets += 1\n",
    "            precision = pos_targets / count\n",
    "            recall = pos_targets / total_positives\n",
    "            for thresh in thresholds:\n",
    "                if recall >= thresh:\n",
    "                    max_prec[thresh] = max(max_prec[thresh], precision)\n",
    "\n",
    "            if pos_targets == total_positives:\n",
    "                break\n",
    "        l = list(max_prec.values())\n",
    "        average_precision = sum(l) / len(l)\n",
    "        ap_place_dict[get_place_name_from_mapping(i)] = average_precision\n",
    "\n",
    "    # ap metrics\n",
    "    incident_map = 0\n",
    "    for incident, ap in ap_incident_dict.items():\n",
    "        incident_map += ap\n",
    "    incident_map /= len(ap_incident_dict)\n",
    "\n",
    "    place_map = 0\n",
    "    for place, ap in ap_place_dict.items():\n",
    "        place_map += ap\n",
    "    place_map /= len(ap_place_dict)\n",
    "\n",
    "    print(\"incident map\", incident_map)\n",
    "    print(\"place map\", place_map)\n",
    "    print(\"incident top1\", top1_num_correct_all / top1_num_total_all)\n",
    "    print(\"incident top5\", top5_num_correct_all / top5_num_total_all)\n",
    "    return incident_map + place_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "train_set = get_dataset(train_paths, train_dir, 200)\n",
    "val_set = get_dataset(val_paths, val_dir, 200)\n",
    "\n",
    "train_df = pd.DataFrame(train_set)\n",
    "val_df = pd.DataFrame(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data loader\"\"\"\n",
    "\n",
    "imgen = ImageDataGenerator(\n",
    "    preprocessing_function=getpreprocessfunc(),\n",
    ")\n",
    "\n",
    "imgen = imgen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    directory=val_dir,\n",
    "    x_col=\"path\",\n",
    "    y_col=[\"incidents\", \"place\"],\n",
    "    weight_col=None,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=None,\n",
    "    class_mode=\"multi_output\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=True,\n",
    "    save_to_dir=None,\n",
    "    save_prefix=\"\",\n",
    "    save_format=\"png\",\n",
    "    subset=None,\n",
    "    interpolation=\"nearest\",\n",
    "    validate_filenames=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model Initialization\"\"\"\n",
    "\n",
    "import resnet\n",
    "\n",
    "trunk = resnet.trunk()\n",
    "resnet.init_weights_from_torch(trunk, \"/kuacc/users/asafaya19/IncidentsDataset/pretrained_weights/eccv_final_model_trunk.pth.tar\")\n",
    "\n",
    "place_w = np.load(os.path.join(abs_path,'models/place_w.npy')).T\n",
    "place_b = np.load(os.path.join(abs_path,'models/place_b.npy')).T\n",
    "incident_w = np.load(os.path.join(abs_path,'models/incident_w.npy')).T\n",
    "incident_b = np.load(os.path.join(abs_path,'models/incident_b.npy')).T\n",
    "\n",
    "mdl = FinalModel(trunk, [incident_w, incident_b], [place_w, place_b])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-5)\n",
    "\n",
    "losses = {\n",
    "    \"output_1\": weighted_loss,\n",
    "    \"output_2\": weighted_loss,\n",
    "}\n",
    "\n",
    "mdl.compile(optimizer=opt, loss=losses, metrics=[get_weighted_accuracy()])\n",
    "\n",
    "x, y = next(imgen)\n",
    "o = mdl(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [0/745]\tIncident Prec@1 27.079 (27.079)\tPlace Prec@1 7.306 (7.306)\tPlace Prec@5 12.010 (12.010)\tIncident Prec@5 30.752 (30.752)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/Image.py:952: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/Image.py:2837: DecompressionBombWarning: Image size (134599200 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [100/745]\tIncident Prec@1 37.152 (33.064)\tPlace Prec@1 9.594 (9.523)\tPlace Prec@5 19.372 (18.848)\tIncident Prec@5 40.633 (37.305)\t\n",
      "Evaluating: [200/745]\tIncident Prec@1 23.315 (32.534)\tPlace Prec@1 7.640 (9.401)\tPlace Prec@5 19.589 (18.993)\tIncident Prec@5 26.339 (36.870)\t\n",
      "Evaluating: [300/745]\tIncident Prec@1 35.895 (32.309)\tPlace Prec@1 15.575 (9.290)\tPlace Prec@5 27.026 (18.874)\tIncident Prec@5 47.329 (36.713)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9 bytes but only got 8. Skipping tag 33432\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [400/745]\tIncident Prec@1 46.454 (32.406)\tPlace Prec@1 6.446 (9.182)\tPlace Prec@5 16.314 (18.830)\tIncident Prec@5 48.503 (36.848)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 36 bytes but only got 35. Skipping tag 33432\n",
      "  \"Possibly corrupt EXIF data.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: [500/745]\tIncident Prec@1 42.440 (32.690)\tPlace Prec@1 11.044 (9.325)\tPlace Prec@5 18.325 (18.964)\tIncident Prec@5 45.501 (37.127)\t\n",
      "Evaluating: [600/745]\tIncident Prec@1 41.597 (32.851)\tPlace Prec@1 11.932 (9.291)\tPlace Prec@5 19.311 (18.982)\tIncident Prec@5 45.614 (37.287)\t\n",
      "Evaluating: [700/745]\tIncident Prec@1 32.385 (32.875)\tPlace Prec@1 13.051 (9.292)\tPlace Prec@5 21.859 (18.975)\tIncident Prec@5 40.435 (37.356)\t\n",
      "\n",
      "Calculating APs\n",
      "\n",
      "incident map 0.6363688474912388\n",
      "place map 0.1550042201700387\n",
      "incident top1 0.32969336966341245\n",
      "incident top5 0.37456993258006455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7913730676612775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgen.reset()\n",
    "validate(imgen, mdl, val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5715/1029726 [04:01<9:55:21, 28.67it/s] /kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "  4%|▍         | 44578/1029726 [33:28<13:40:27, 20.01it/s] /kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:771: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 6. Skipping tag 41487\n",
      "  \"Possibly corrupt EXIF data.  \"\n",
      "  5%|▍         | 46617/1029726 [34:48<16:14:28, 16.81it/s]/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:599: UserWarning: Metadata Warning, tag 296 had too many entries: 2, expected 1\n",
      "  f\"Metadata Warning, tag {tag} had too many entries: \"\n",
      " 11%|█▏        | 116627/1029726 [1:20:49<5:53:28, 43.05it/s] /kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/Image.py:2837: DecompressionBombWarning: Image size (153603000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n",
      " 14%|█▍        | 144223/1029726 [1:43:35<11:59:55, 20.50it/s]/kuacc/users/asafaya19/anaconda3/envs/ml-graphs/lib/python3.7/site-packages/PIL/JpegImagePlugin.py:792: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file\n",
      "  \"Image appears to be a malformed MPO file, it will be \"\n",
      " 15%|█▌        | 155208/1029726 [1:52:50<8:22:20, 29.01it/s] "
     ]
    }
   ],
   "source": [
    "train_set = get_dataset(train_paths, train_dir, 20000000)\n",
    "train_df = pd.DataFrame(train_set)\n",
    "\n",
    "imgen = ImageDataGenerator(\n",
    "    preprocessing_function=getpreprocessfunc(),\n",
    ")\n",
    "\n",
    "imgen = imgen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=train_dir,\n",
    "    x_col=\"path\",\n",
    "    y_col=[\"incidents\", \"place\"],\n",
    "    weight_col=None,\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    classes=None,\n",
    "    class_mode=\"multi_output\",\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    seed=True,\n",
    "    save_to_dir=None,\n",
    "    save_prefix=\"\",\n",
    "    save_format=\"png\",\n",
    "    subset=None,\n",
    "    interpolation=\"nearest\",\n",
    "    validate_filenames=False,\n",
    ")\n",
    "\n",
    "imgen.reset()\n",
    "validate(imgen, mdl, train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
